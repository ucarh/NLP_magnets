{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load configuration\n",
    "con_file = open(\"config.json\")\n",
    "config = json.load(con_file)\n",
    "con_file.close()\n",
    "\n",
    "## Initialize client`\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(doi,outfile):\n",
    "    doi_doc = FullDoc(doi = doi)\n",
    "    \n",
    "    if doi_doc.read(client):\n",
    "        try:\n",
    "            title = doi_doc.title\n",
    "        except:\n",
    "            title=\"\"\n",
    "        try:\n",
    "            abstract = doi_doc.data['coredata']['dc:description']\n",
    "        except:\n",
    "            abstract=\"\"\n",
    "            \n",
    "        try:\n",
    "            text = doi_doc.data['originalText']\n",
    "        except:\n",
    "            text=None\n",
    "\n",
    "        #some articles start with Introduction, some start with 1 Introduction\n",
    "        if isinstance(text,str):\n",
    "            if '1 Introduction' not in text:\n",
    "                introduction=text.find('Introduction',text.find('Introduction')+1)\n",
    "            else:\n",
    "                introduction=text.find('1 Introduction',text.find('1 Introduction')+1)\n",
    "\n",
    "        \n",
    "        # Section number for the Conclusion(s) section varies, so used regex to catch those.\n",
    "        # +-750 is a heuristic number. Wanted to capture a few sentences in the conclusion section.\n",
    "            try:\n",
    "                regex=re.compile(r'\\d+\\sConclusions')\n",
    "                conclusions_occurence=regex.findall(text)[0]\n",
    "                conclusions_start=text.find(conclusions_occurence,text.find(conclusions_occurence)+1)\n",
    "                filtered_text=text[introduction:conclusions_start+750].strip()\n",
    "                # print('regex 1 found')\n",
    "            except:\n",
    "                try:\n",
    "                    regex=re.compile(r'\\d+\\sConclusion')\n",
    "                    conclusions_occurence=regex.findall(text)[0]\n",
    "                    conclusions_start=text.find(conclusions_occurence,text.find(conclusions_occurence)+1)\n",
    "                    filtered_text=text[introduction:conclusions_start+750].strip()\n",
    "                    # print('regex 2 found')\n",
    "\n",
    "        #If conclusions section is not present, use References [1] or References to get the end of the article\n",
    "                except:\n",
    "                    if 'References [1]' not in text:\n",
    "                        reference_start = text.find('References',text.find('References')+1)\n",
    "                    else:\n",
    "                        reference_start = text.find(\"References [1]\")\n",
    "                    filtered_text = text[introduction:reference_start-1000].strip()\n",
    "                    # print('regex NOT found')\n",
    "            \n",
    "            json.dump({'title': title, 'abstract': abstract, 'text': filtered_text,'doi':doi}, outfile)\n",
    "        else:\n",
    "            filtered_text=\"Text is not string.\"\n",
    "            json.dump({'title': title, 'abstract': abstract, 'text': filtered_text,'doi':doi}, outfile)\n",
    "          \n",
    "    else:\n",
    "        filtered_text=\"Read document failed.\"\n",
    "        json.dump({'title': title, 'abstract': abstract, 'text': filtered_text,'doi':doi}, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023=pd.read_csv('./DOI_Elsevier_magnetic/2023_Elsevier_data.csv')\n",
    "DOI_list=df_2023['DOI'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a \"./data/2023_magnetic_corpus.jsonl\" file.\n",
    "count=1\n",
    "with open('data/2023_magnetic_corpus.jsonl', 'w') as outfile:\n",
    "    for doi in DOI_list:\n",
    "        with open(\"data/2023_magnetic_corpus_progress.txt\",\"a\") as file:\n",
    "            file.write(f\"working on doi:{doi}, step {count}/{len(DOI_list)} \\n\")\n",
    "        count+=1\n",
    "        \n",
    "        create_dataset(doi, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnetics_data=load_dataset(\"json\",data_files=\"./data/2023_magnetic_corpus.jsonl\",split='train')\n",
    "# magnetics_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "# magnetics_data.push_to_hub(\"nlp-magnets/2023_magnetics_corpus\",private=True,split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53da578a22ba4cc6ae0e277b28bf5884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89802b9a2fc4464fbe302f153a8bdeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e2563febb94f59b02c17215e9f5649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/98.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e67de28d1544cdb0e6014429b34409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b3afd4f7974d5399094ba650d8dfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7790 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "magnetics_data_hugginface=load_dataset('nlp-magnets/2023_magnetics_corpus',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'abstract', 'text', 'doi'],\n",
       "    num_rows: 7790\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total data records is 7790 from 2023.\n",
    "magnetics_data_hugginface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15fa98afbdb44ff872cd5196a5b0fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7790 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'abstract', 'text', 'doi'],\n",
       "    num_rows: 6382\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# about 1500 articles were not read properly or we don't have subscription from 2023.\n",
    "filtered_data=magnetics_data_hugginface.filter(lambda x: len(x['text'])>100)\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9a546b9a7c4ec79ae4844bc93eeffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'abstract', 'text', 'doi'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# about 30 articles have None values, but there is text.\n",
    "filtered_data.filter(lambda x: x['abstract']==None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
